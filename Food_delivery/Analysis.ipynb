{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:05.760043Z",
     "start_time": "2025-07-19T14:33:04.143086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "Requirement already satisfied: kagglehub in /opt/conda/lib/python3.9/site-packages (0.3.12)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from kagglehub) (4.62.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from kagglehub) (2.26.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from kagglehub) (6.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from kagglehub) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->kagglehub) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->kagglehub) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->kagglehub) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->kagglehub) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->kagglehub) (3.3)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.1.5)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "Collecting numpy>=1.22.4\n",
      "  Using cached numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "Installing collected packages: numpy, pandas\n",
      "  Attempting uninstall: numpy\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "    Found existing installation: numpy 1.21.3\n",
      "    Uninstalling numpy-1.21.3:\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: 'REQUESTED'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/romanniki/food-delivery-cost-and-profitability?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 28.0k/28.0k [00:00<00:00, 1.26MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Archivo encontrado: /home/jovyan/.cache/kagglehub/datasets/romanniki/food-delivery-cost-and-profitability/versions/1/food_orders_new_delhi (1).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "\n",
    "dataset_path = kagglehub.dataset_download(\"romanniki/food-delivery-cost-and-profitability\")\n",
    "\n",
    "# Mostrar todos los archivos encontrados\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        print(\"Archivo encontrado:\", os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.366181Z",
     "start_time": "2025-07-19T14:33:05.839196Z"
    },
    "id": "DZiXESZ8UiEb"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Descarga el dataset (o usa el caché)\n",
    "romanniki_food_delivery_cost_and_profitability_path = kagglehub.dataset_download('romanniki/food-delivery-cost-and-profitability')\n",
    "\n",
    "# Buscar el primer archivo dentro del dataset descargado\n",
    "for root, dirs, files in os.walk(romanniki_food_delivery_cost_and_profitability_path):\n",
    "    for file in files:\n",
    "        path_dataset = os.path.abspath(os.path.join(root, file))\n",
    "        break  # solo el primero\n",
    "    else:\n",
    "        continue\n",
    "    break\n",
    "\n",
    "print('Data source import complete.')\n",
    "print(\"Archivo encontrado en:\", path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.391946Z",
     "start_time": "2025-07-19T14:33:06.388433Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.440900Z",
     "start_time": "2025-07-19T14:33:06.406096Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_dataset)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.519151Z",
     "start_time": "2025-07-19T14:33:06.456124Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convertir fechas a tipo datetime\n",
    "df['Order Date and Time'] = pd.to_datetime(df['Order Date and Time'])\n",
    "df['Delivery Date and Time'] = pd.to_datetime(df['Delivery Date and Time'])\n",
    "\n",
    "# Crear columna de tiempo de entrega en minutos\n",
    "df['Delivery Duration (min)'] = (df['Delivery Date and Time'] - df['Order Date and Time']).dt.total_seconds() / 60\n",
    "# Extraer día y hora del pedido\n",
    "df['day_of_week'] = df['Order Date and Time'].dt.day_name()\n",
    "df['hour_of_day'] = df['Order Date and Time'].dt.hour\n",
    "# Marcar si hay descuento o no\n",
    "df['has_discount'] = df['Discounts and Offers'].str.lower() != 'none'\n",
    "\n",
    "# Marcar si fue reembolsado\n",
    "df['refunded'] = df['Refunds/Chargebacks'] > 0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.604977Z",
     "start_time": "2025-07-19T14:33:06.599652Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df['Discounts and Offers'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.686032Z",
     "start_time": "2025-07-19T14:33:06.658804Z"
    }
   },
   "outputs": [],
   "source": [
    "def calcular_descuento(row):\n",
    "    valor = str(row['Discounts and Offers']).lower()\n",
    "    pedido = row['Order Value']\n",
    "    \n",
    "    # Si es porcentaje, por ejemplo \"10%\" o \"5% on app\"\n",
    "    if '%' in valor:\n",
    "        try:\n",
    "            porcentaje = float(valor.split('%')[0])\n",
    "            return pedido * (porcentaje / 100)\n",
    "        except:\n",
    "            return 0\n",
    "        \n",
    "    # Si es \"50 off Promo\" u otros con valor fijo\n",
    "    elif 'off' in valor:\n",
    "        for token in valor.split():\n",
    "            try:\n",
    "                return float(token)\n",
    "            except:\n",
    "                continue\n",
    "        return 0\n",
    "\n",
    "    # Si es \"None\" u otra cosa no reconocida\n",
    "    return 0\n",
    "\n",
    "# Aplicar al DataFrame\n",
    "df['Discount Value'] = df.apply(calcular_descuento, axis=1)\n",
    "\n",
    "# Verificar\n",
    "df[['Discounts and Offers', 'Order Value', 'Discount Value']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.744183Z",
     "start_time": "2025-07-19T14:33:06.738421Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Total Cost'] = df['Delivery Fee'] + df['Discount Value'] + df['Payment Processing Fee'] + df['Refunds/Chargebacks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.793022Z",
     "start_time": "2025-07-19T14:33:06.784037Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Profit'] = df['Commission Fee'] - df['Total Cost']\n",
    "\n",
    "# Estadísticas generales\n",
    "print(\"Ganancia media por pedido:\", round(df['Profit'].mean(), 2))\n",
    "print(\"Pedidos con pérdida:\", (df['Profit'] < 0).sum())\n",
    "print(\"Porcentaje con pérdida:\", round((df['Profit'] < 0).mean() * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.827019Z",
     "start_time": "2025-07-19T14:33:06.815908Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mostrar los 10 pedidos con mayores pérdidas (menor Profit)\n",
    "top_losses = df.sort_values(by='Profit').tail(10)\n",
    "\n",
    "# Mostrar solo las columnas clave para el análisis\n",
    "top_losses[[ 'Order Value', 'Commission Fee', 'Total Cost', 'Profit', 'Discounts and Offers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.874830Z",
     "start_time": "2025-07-19T14:33:06.862986Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRAFICOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:07.403158Z",
     "start_time": "2025-07-19T14:33:06.925091Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(df.select_dtypes(include=['number']).corr(), annot=True, fmt='.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:07.560809Z",
     "start_time": "2025-07-19T14:33:07.423773Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(data=df, x='day_of_week', y='Delivery Duration (min)', \n",
    "            order=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Duración de entrega por día de la semana\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:07.763033Z",
     "start_time": "2025-07-19T14:33:07.578110Z"
    }
   },
   "outputs": [],
   "source": [
    "top_restaurants = df['Restaurant ID'].value_counts().nlargest(10).index\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(data=df[df['Restaurant ID'].isin(top_restaurants)],\n",
    "            x='Restaurant ID', y='Delivery Duration (min)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Top 10 restaurantes vs duración de entrega\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:07.849801Z",
     "start_time": "2025-07-19T14:33:07.778800Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(data=df, x='has_discount', y='Delivery Duration (min)')\n",
    "plt.title(\"Duración con/sin descuento\")\n",
    "plt.xlabel(\"¿Tiene descuento?\")\n",
    "plt.ylabel(\"Duración (min)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:07.954801Z",
     "start_time": "2025-07-19T14:33:07.865268Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(data=df, x='Payment Method', y='Delivery Duration (min)')\n",
    "plt.title(\"Método de pago vs duración de entrega\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:08.050806Z",
     "start_time": "2025-07-19T14:33:07.970379Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(data=df, x='refunded', y='Delivery Duration (min)')\n",
    "plt.title(\"Reembolsos vs duración de entrega\")\n",
    "plt.xlabel(\"¿Fue reembolsado?\")\n",
    "plt.ylabel(\"Duración (min)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:08.332802Z",
     "start_time": "2025-07-19T14:33:08.065785Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "sns.boxplot(data=df, x='hour_of_day', y='Delivery Duration (min)')\n",
    "plt.title(\"Duración según hora del pedido\")\n",
    "plt.xlabel(\"Hora del día\")\n",
    "plt.ylabel(\"Duración (min)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:08.517808Z",
     "start_time": "2025-07-19T14:33:08.347830Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df['Profit'], bins=50, kde=True)\n",
    "plt.title(\"Distribución de la ganancia por pedido\")\n",
    "plt.xlabel(\"Ganancia\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:08.674807Z",
     "start_time": "2025-07-19T14:33:08.531825Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Asegurarnos de que la columna tenga un nombre limpio (por si no lo hiciste antes)\n",
    "df['Discounts and Offers'] = df['Discounts and Offers'].astype(str)\n",
    "\n",
    "# Agrupar por tipo de descuento y calcular profit promedio\n",
    "profit_por_descuento = df.groupby('Discounts and Offers')['Profit'].mean().sort_values()\n",
    "\n",
    "# Crear gráfico\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=profit_por_descuento.values, y=profit_por_descuento.index, palette='coolwarm')\n",
    "plt.title(\"Ganancia media por tipo de descuento\")\n",
    "plt.xlabel(\"Ganancia media (Profit)\")\n",
    "plt.ylabel(\"Tipo de descuento\")\n",
    "plt.axvline(0, color='gray', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:08.795803Z",
     "start_time": "2025-07-19T14:33:08.688932Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Asegúrate de que la columna de duración esté creada\n",
    "if 'Delivery Duration (min)' not in df.columns:\n",
    "    df['Order Date and Time'] = pd.to_datetime(df['Order Date and Time'])\n",
    "    df['Delivery Date and Time'] = pd.to_datetime(df['Delivery Date and Time'])\n",
    "    df['Delivery Duration (min)'] = (df['Delivery Date and Time'] - df['Order Date and Time']).dt.total_seconds() / 60\n",
    "\n",
    "# Crear columna binaria: ¿Hubo reembolso?\n",
    "df['Refunded'] = df['Refunds/Chargebacks'] > 0\n",
    "\n",
    "# Gráfico de distribución del tiempo de entrega según haya o no reembolso\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x='Refunded', y='Delivery Duration (min)', data=df)\n",
    "plt.xticks([0,1], ['Sin reembolso', 'Con reembolso'])\n",
    "plt.title(\"Tiempo de entrega según presencia de reembolso\")\n",
    "plt.ylabel(\"Duración de entrega (minutos)\")\n",
    "plt.xlabel(\"¿Hubo reembolso?\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:08.976938Z",
     "start_time": "2025-07-19T14:33:08.810855Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.kdeplot(df[df['Refunded'] == False]['Delivery Duration (min)'], label='Sin reembolso', shade=True)\n",
    "sns.kdeplot(df[df['Refunded'] == True]['Delivery Duration (min)'], label='Con reembolso', shade=True)\n",
    "plt.title(\"Distribución del tiempo de entrega según reembolso\")\n",
    "plt.xlabel(\"Duración de entrega (minutos)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:09.190808Z",
     "start_time": "2025-07-19T14:33:08.993746Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.kdeplot(df[df['Refunded'] == False]['Order Value'], label='Sin reembolso', shade=True)\n",
    "sns.kdeplot(df[df['Refunded'] == True]['Order Value'], label='Con reembolso', shade=True)\n",
    "plt.title(\"Distribución del Order Value según reembolso\")\n",
    "plt.xlabel(\"Order Value (INR)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:09.210824Z",
     "start_time": "2025-07-19T14:33:09.207015Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizar columnas en pandas\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "# Eliminar espacios y duplicados en nombres de columnas\n",
    "df.columns = pd.io.parsers.ParserBase({'names': df.columns})._maybe_dedup_names(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:09.235823Z",
     "start_time": "2025-07-19T14:33:09.222952Z"
    }
   },
   "outputs": [],
   "source": [
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:34:40.666100Z",
     "start_time": "2025-07-19T14:33:09.261662Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "# Cerrar contexto anterior si está activo\n",
    "if SparkContext._active_spark_context:\n",
    "    SparkContext._active_spark_context.stop()\n",
    "\n",
    "# SparkSession apuntando al cluster\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"DeliveryDurationGBT-Tuned-Light\")\n",
    "    .master(\"spark://agile:7077\")\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Añadir columnas derivadas en pandas antes de pasar a Spark\n",
    "df[\"es_fin_de_semana\"] = df[\"day_of_week\"].isin([\"Saturday\", \"Sunday\"]).astype(int)\n",
    "df[\"es_hora_punta\"] = df[\"hour_of_day\"].between(13, 15) | df[\"hour_of_day\"].between(20, 22)\n",
    "df[\"es_hora_punta\"] = df[\"es_hora_punta\"].astype(int)\n",
    "\n",
    "# Crear DataFrame en Spark\n",
    "df_spark = spark.createDataFrame(df)\n",
    "\n",
    "# Variables\n",
    "categorical_cols = ['payment_method', 'discounts_and_offers', 'day_of_week', 'hour_of_day']\n",
    "numeric_cols = [\n",
    "    'order_value', 'delivery_fee', 'commission_fee', 'payment_processing_fee',\n",
    "    'refunds/chargebacks', 'discount_value', 'has_discount', 'refunded',\n",
    "    'es_fin_de_semana', 'es_hora_punta'\n",
    "]\n",
    "target = 'delivery_duration_(min)'\n",
    "\n",
    "# Indexado y one-hot\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_idx\", handleInvalid=\"keep\") for col in categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCol=col + \"_idx\", outputCol=col + \"_vec\") for col in categorical_cols]\n",
    "\n",
    "# Vector de features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=numeric_cols + [col + \"_vec\" for col in categorical_cols],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Modelo\n",
    "regressor = GBTRegressor(featuresCol=\"features\", labelCol=target)\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, regressor])\n",
    "\n",
    "# Grid de hiperparámetros ligera\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(regressor.maxDepth, [5]) \\\n",
    "    .addGrid(regressor.maxIter, [20, 40]) \\\n",
    "    .build()\n",
    "\n",
    "# Train-validation split\n",
    "tvs = TrainValidationSplit(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"rmse\"),\n",
    "    trainRatio=0.8\n",
    ")\n",
    "\n",
    "# Split de datos\n",
    "train_data, test_data = df_spark.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Entrenamiento\n",
    "# tvs_model = tvs.fit(train_data)\n",
    "tvs_model = pipeline.fit(train_data)\n",
    "\n",
    "# Evaluación\n",
    "predictions = tvs_model.transform(test_data)\n",
    "rmse = RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"rmse\").evaluate(predictions)\n",
    "\n",
    "print(\"✅ Modelo mejorado con TrainValidationSplit\")\n",
    "print(f\"📉 RMSE final: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:36:29.489847Z",
     "start_time": "2025-07-19T14:36:26.618289Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convertimos a Pandas para visualización\n",
    "preds_pd = predictions.select(\"delivery_duration_(min)\", \"prediction\").toPandas()\n",
    "\n",
    "# Plot real vs predicho\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(preds_pd[\"delivery_duration_(min)\"], preds_pd[\"prediction\"], alpha=0.5)\n",
    "plt.plot([0, preds_pd.max().max()], [0, preds_pd.max().max()], 'r--')\n",
    "plt.xlabel(\"Valor real\")\n",
    "plt.ylabel(\"Predicción\")\n",
    "plt.title(\"Predicción vs Real (Duración en minutos)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:36:30.651045Z",
     "start_time": "2025-07-19T14:36:29.555718Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mostrar predicciones reales vs. predichas\n",
    "predictions.select('delivery_duration_(min)', 'prediction').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_path = \"./models\"\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "# Guarda el VectorAssembler\n",
    "assembler.write().overwrite().save(f\"{base_path}/vector_assembler.bin\")\n",
    "\n",
    "# Guarda todos los StringIndexer\n",
    "for idx, indexer_model in enumerate(indexers):\n",
    "    indexer_model.write().overwrite().save(f\"{base_path}/string_indexer_{idx}.bin\")\n",
    "\n",
    "# Guarda todos los OneHotEncoder\n",
    "for idx, encoder_model in enumerate(encoders):\n",
    "    encoder_model.write().overwrite().save(f\"{base_path}/one_hot_encoder_{idx}.bin\")\n",
    "\n",
    "# Guarda el modelo entrenado\n",
    "tvs_model.write().overwrite().save(f\"{base_path}/pipeline_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Food Delivery: Timing is everything",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5072200,
     "sourceId": 8499662,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
