{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:05.760043Z",
     "start_time": "2025-07-19T14:33:04.143086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "Requirement already satisfied: kagglehub in /opt/conda/lib/python3.9/site-packages (0.3.12)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from kagglehub) (4.62.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from kagglehub) (2.26.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from kagglehub) (6.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from kagglehub) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->kagglehub) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->kagglehub) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->kagglehub) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->kagglehub) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->kagglehub) (3.3)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.1.5)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "Collecting numpy>=1.22.4\n",
      "  Using cached numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "Installing collected packages: numpy, pandas\n",
      "  Attempting uninstall: numpy\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "    Found existing installation: numpy 1.21.3\n",
      "    Uninstalling numpy-1.21.3:\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: 'REQUESTED'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/romanniki/food-delivery-cost-and-profitability?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 28.0k/28.0k [00:00<00:00, 1.26MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Archivo encontrado: /home/jovyan/.cache/kagglehub/datasets/romanniki/food-delivery-cost-and-profitability/versions/1/food_orders_new_delhi (1).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "\n",
    "dataset_path = kagglehub.dataset_download(\"romanniki/food-delivery-cost-and-profitability\")\n",
    "\n",
    "# Mostrar todos los archivos encontrados\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        print(\"Archivo encontrado:\", os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.366181Z",
     "start_time": "2025-07-19T14:33:05.839196Z"
    },
    "id": "DZiXESZ8UiEb"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Descarga el dataset (o usa el cach√©)\n",
    "romanniki_food_delivery_cost_and_profitability_path = kagglehub.dataset_download('romanniki/food-delivery-cost-and-profitability')\n",
    "\n",
    "# Buscar el primer archivo dentro del dataset descargado\n",
    "for root, dirs, files in os.walk(romanniki_food_delivery_cost_and_profitability_path):\n",
    "    for file in files:\n",
    "        path_dataset = os.path.abspath(os.path.join(root, file))\n",
    "        break  # solo el primero\n",
    "    else:\n",
    "        continue\n",
    "    break\n",
    "\n",
    "print('Data source import complete.')\n",
    "print(\"Archivo encontrado en:\", path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.391946Z",
     "start_time": "2025-07-19T14:33:06.388433Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.440900Z",
     "start_time": "2025-07-19T14:33:06.406096Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_dataset)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.519151Z",
     "start_time": "2025-07-19T14:33:06.456124Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convertir fechas a tipo datetime\n",
    "df['Order Date and Time'] = pd.to_datetime(df['Order Date and Time'])\n",
    "df['Delivery Date and Time'] = pd.to_datetime(df['Delivery Date and Time'])\n",
    "\n",
    "# Crear columna de tiempo de entrega en minutos\n",
    "df['Delivery Duration (min)'] = (df['Delivery Date and Time'] - df['Order Date and Time']).dt.total_seconds() / 60\n",
    "# Extraer d√≠a y hora del pedido\n",
    "df['day_of_week'] = df['Order Date and Time'].dt.day_name()\n",
    "df['hour_of_day'] = df['Order Date and Time'].dt.hour\n",
    "# Marcar si hay descuento o no\n",
    "df['has_discount'] = df['Discounts and Offers'].str.lower() != 'none'\n",
    "\n",
    "# Marcar si fue reembolsado\n",
    "df['refunded'] = df['Refunds/Chargebacks'] > 0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.604977Z",
     "start_time": "2025-07-19T14:33:06.599652Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df['Discounts and Offers'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.686032Z",
     "start_time": "2025-07-19T14:33:06.658804Z"
    }
   },
   "outputs": [],
   "source": [
    "def calcular_descuento(row):\n",
    "    valor = str(row['Discounts and Offers']).lower()\n",
    "    pedido = row['Order Value']\n",
    "    \n",
    "    # Si es porcentaje, por ejemplo \"10%\" o \"5% on app\"\n",
    "    if '%' in valor:\n",
    "        try:\n",
    "            porcentaje = float(valor.split('%')[0])\n",
    "            return pedido * (porcentaje / 100)\n",
    "        except:\n",
    "            return 0\n",
    "        \n",
    "    # Si es \"50 off Promo\" u otros con valor fijo\n",
    "    elif 'off' in valor:\n",
    "        for token in valor.split():\n",
    "            try:\n",
    "                return float(token)\n",
    "            except:\n",
    "                continue\n",
    "        return 0\n",
    "\n",
    "    # Si es \"None\" u otra cosa no reconocida\n",
    "    return 0\n",
    "\n",
    "# Aplicar al DataFrame\n",
    "df['Discount Value'] = df.apply(calcular_descuento, axis=1)\n",
    "\n",
    "# Verificar\n",
    "df[['Discounts and Offers', 'Order Value', 'Discount Value']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.744183Z",
     "start_time": "2025-07-19T14:33:06.738421Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Total Cost'] = df['Delivery Fee'] + df['Discount Value'] + df['Payment Processing Fee'] + df['Refunds/Chargebacks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.793022Z",
     "start_time": "2025-07-19T14:33:06.784037Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Profit'] = df['Commission Fee'] - df['Total Cost']\n",
    "\n",
    "# Estad√≠sticas generales\n",
    "print(\"Ganancia media por pedido:\", round(df['Profit'].mean(), 2))\n",
    "print(\"Pedidos con p√©rdida:\", (df['Profit'] < 0).sum())\n",
    "print(\"Porcentaje con p√©rdida:\", round((df['Profit'] < 0).mean() * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.827019Z",
     "start_time": "2025-07-19T14:33:06.815908Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mostrar los 10 pedidos con mayores p√©rdidas (menor Profit)\n",
    "top_losses = df.sort_values(by='Profit').tail(10)\n",
    "\n",
    "# Mostrar solo las columnas clave para el an√°lisis\n",
    "top_losses[[ 'Order Value', 'Commission Fee', 'Total Cost', 'Profit', 'Discounts and Offers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:06.874830Z",
     "start_time": "2025-07-19T14:33:06.862986Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRAFICOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:07.403158Z",
     "start_time": "2025-07-19T14:33:06.925091Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(df.select_dtypes(include=['number']).corr(), annot=True, fmt='.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:07.560809Z",
     "start_time": "2025-07-19T14:33:07.423773Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(data=df, x='day_of_week', y='Delivery Duration (min)', \n",
    "            order=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Duraci√≥n de entrega por d√≠a de la semana\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:07.763033Z",
     "start_time": "2025-07-19T14:33:07.578110Z"
    }
   },
   "outputs": [],
   "source": [
    "top_restaurants = df['Restaurant ID'].value_counts().nlargest(10).index\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(data=df[df['Restaurant ID'].isin(top_restaurants)],\n",
    "            x='Restaurant ID', y='Delivery Duration (min)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Top 10 restaurantes vs duraci√≥n de entrega\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:07.849801Z",
     "start_time": "2025-07-19T14:33:07.778800Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(data=df, x='has_discount', y='Delivery Duration (min)')\n",
    "plt.title(\"Duraci√≥n con/sin descuento\")\n",
    "plt.xlabel(\"¬øTiene descuento?\")\n",
    "plt.ylabel(\"Duraci√≥n (min)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:07.954801Z",
     "start_time": "2025-07-19T14:33:07.865268Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(data=df, x='Payment Method', y='Delivery Duration (min)')\n",
    "plt.title(\"M√©todo de pago vs duraci√≥n de entrega\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:08.050806Z",
     "start_time": "2025-07-19T14:33:07.970379Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(data=df, x='refunded', y='Delivery Duration (min)')\n",
    "plt.title(\"Reembolsos vs duraci√≥n de entrega\")\n",
    "plt.xlabel(\"¬øFue reembolsado?\")\n",
    "plt.ylabel(\"Duraci√≥n (min)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:08.332802Z",
     "start_time": "2025-07-19T14:33:08.065785Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "sns.boxplot(data=df, x='hour_of_day', y='Delivery Duration (min)')\n",
    "plt.title(\"Duraci√≥n seg√∫n hora del pedido\")\n",
    "plt.xlabel(\"Hora del d√≠a\")\n",
    "plt.ylabel(\"Duraci√≥n (min)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:08.517808Z",
     "start_time": "2025-07-19T14:33:08.347830Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df['Profit'], bins=50, kde=True)\n",
    "plt.title(\"Distribuci√≥n de la ganancia por pedido\")\n",
    "plt.xlabel(\"Ganancia\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:08.674807Z",
     "start_time": "2025-07-19T14:33:08.531825Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Asegurarnos de que la columna tenga un nombre limpio (por si no lo hiciste antes)\n",
    "df['Discounts and Offers'] = df['Discounts and Offers'].astype(str)\n",
    "\n",
    "# Agrupar por tipo de descuento y calcular profit promedio\n",
    "profit_por_descuento = df.groupby('Discounts and Offers')['Profit'].mean().sort_values()\n",
    "\n",
    "# Crear gr√°fico\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=profit_por_descuento.values, y=profit_por_descuento.index, palette='coolwarm')\n",
    "plt.title(\"Ganancia media por tipo de descuento\")\n",
    "plt.xlabel(\"Ganancia media (Profit)\")\n",
    "plt.ylabel(\"Tipo de descuento\")\n",
    "plt.axvline(0, color='gray', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:08.795803Z",
     "start_time": "2025-07-19T14:33:08.688932Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Aseg√∫rate de que la columna de duraci√≥n est√© creada\n",
    "if 'Delivery Duration (min)' not in df.columns:\n",
    "    df['Order Date and Time'] = pd.to_datetime(df['Order Date and Time'])\n",
    "    df['Delivery Date and Time'] = pd.to_datetime(df['Delivery Date and Time'])\n",
    "    df['Delivery Duration (min)'] = (df['Delivery Date and Time'] - df['Order Date and Time']).dt.total_seconds() / 60\n",
    "\n",
    "# Crear columna binaria: ¬øHubo reembolso?\n",
    "df['Refunded'] = df['Refunds/Chargebacks'] > 0\n",
    "\n",
    "# Gr√°fico de distribuci√≥n del tiempo de entrega seg√∫n haya o no reembolso\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x='Refunded', y='Delivery Duration (min)', data=df)\n",
    "plt.xticks([0,1], ['Sin reembolso', 'Con reembolso'])\n",
    "plt.title(\"Tiempo de entrega seg√∫n presencia de reembolso\")\n",
    "plt.ylabel(\"Duraci√≥n de entrega (minutos)\")\n",
    "plt.xlabel(\"¬øHubo reembolso?\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:08.976938Z",
     "start_time": "2025-07-19T14:33:08.810855Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.kdeplot(df[df['Refunded'] == False]['Delivery Duration (min)'], label='Sin reembolso', shade=True)\n",
    "sns.kdeplot(df[df['Refunded'] == True]['Delivery Duration (min)'], label='Con reembolso', shade=True)\n",
    "plt.title(\"Distribuci√≥n del tiempo de entrega seg√∫n reembolso\")\n",
    "plt.xlabel(\"Duraci√≥n de entrega (minutos)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:09.190808Z",
     "start_time": "2025-07-19T14:33:08.993746Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.kdeplot(df[df['Refunded'] == False]['Order Value'], label='Sin reembolso', shade=True)\n",
    "sns.kdeplot(df[df['Refunded'] == True]['Order Value'], label='Con reembolso', shade=True)\n",
    "plt.title(\"Distribuci√≥n del Order Value seg√∫n reembolso\")\n",
    "plt.xlabel(\"Order Value (INR)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:09.210824Z",
     "start_time": "2025-07-19T14:33:09.207015Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizar columnas en pandas\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "# Eliminar espacios y duplicados en nombres de columnas\n",
    "df.columns = pd.io.parsers.ParserBase({'names': df.columns})._maybe_dedup_names(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:33:09.235823Z",
     "start_time": "2025-07-19T14:33:09.222952Z"
    }
   },
   "outputs": [],
   "source": [
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:34:40.666100Z",
     "start_time": "2025-07-19T14:33:09.261662Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "# Cerrar contexto anterior si est√° activo\n",
    "if SparkContext._active_spark_context:\n",
    "    SparkContext._active_spark_context.stop()\n",
    "\n",
    "# SparkSession apuntando al cluster\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"DeliveryDurationGBT-Tuned-Light\")\n",
    "    .master(\"spark://agile:7077\")\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "# A√±adir columnas derivadas en pandas antes de pasar a Spark\n",
    "df[\"es_fin_de_semana\"] = df[\"day_of_week\"].isin([\"Saturday\", \"Sunday\"]).astype(int)\n",
    "df[\"es_hora_punta\"] = df[\"hour_of_day\"].between(13, 15) | df[\"hour_of_day\"].between(20, 22)\n",
    "df[\"es_hora_punta\"] = df[\"es_hora_punta\"].astype(int)\n",
    "\n",
    "# Crear DataFrame en Spark\n",
    "df_spark = spark.createDataFrame(df)\n",
    "\n",
    "# Variables\n",
    "categorical_cols = ['payment_method', 'discounts_and_offers', 'day_of_week', 'hour_of_day']\n",
    "numeric_cols = [\n",
    "    'order_value', 'delivery_fee', 'commission_fee', 'payment_processing_fee',\n",
    "    'refunds/chargebacks', 'discount_value', 'has_discount', 'refunded',\n",
    "    'es_fin_de_semana', 'es_hora_punta'\n",
    "]\n",
    "target = 'delivery_duration_(min)'\n",
    "\n",
    "# Indexado y one-hot\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_idx\", handleInvalid=\"keep\") for col in categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCol=col + \"_idx\", outputCol=col + \"_vec\") for col in categorical_cols]\n",
    "\n",
    "# Vector de features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=numeric_cols + [col + \"_vec\" for col in categorical_cols],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Modelo\n",
    "regressor = GBTRegressor(featuresCol=\"features\", labelCol=target)\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, regressor])\n",
    "\n",
    "# Grid de hiperpar√°metros ligera\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(regressor.maxDepth, [5]) \\\n",
    "    .addGrid(regressor.maxIter, [20, 40]) \\\n",
    "    .build()\n",
    "\n",
    "# Train-validation split\n",
    "tvs = TrainValidationSplit(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"rmse\"),\n",
    "    trainRatio=0.8\n",
    ")\n",
    "\n",
    "# Split de datos\n",
    "train_data, test_data = df_spark.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Entrenamiento\n",
    "# tvs_model = tvs.fit(train_data)\n",
    "tvs_model = pipeline.fit(train_data)\n",
    "\n",
    "# Evaluaci√≥n\n",
    "predictions = tvs_model.transform(test_data)\n",
    "rmse = RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"rmse\").evaluate(predictions)\n",
    "\n",
    "print(\"‚úÖ Modelo mejorado con TrainValidationSplit\")\n",
    "print(f\"üìâ RMSE final: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:36:29.489847Z",
     "start_time": "2025-07-19T14:36:26.618289Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convertimos a Pandas para visualizaci√≥n\n",
    "preds_pd = predictions.select(\"delivery_duration_(min)\", \"prediction\").toPandas()\n",
    "\n",
    "# Plot real vs predicho\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(preds_pd[\"delivery_duration_(min)\"], preds_pd[\"prediction\"], alpha=0.5)\n",
    "plt.plot([0, preds_pd.max().max()], [0, preds_pd.max().max()], 'r--')\n",
    "plt.xlabel(\"Valor real\")\n",
    "plt.ylabel(\"Predicci√≥n\")\n",
    "plt.title(\"Predicci√≥n vs Real (Duraci√≥n en minutos)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T14:36:30.651045Z",
     "start_time": "2025-07-19T14:36:29.555718Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mostrar predicciones reales vs. predichas\n",
    "predictions.select('delivery_duration_(min)', 'prediction').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_path = \"./models\"\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "# Guarda el VectorAssembler\n",
    "assembler.write().overwrite().save(f\"{base_path}/vector_assembler.bin\")\n",
    "\n",
    "# Guarda todos los StringIndexer\n",
    "for idx, indexer_model in enumerate(indexers):\n",
    "    indexer_model.write().overwrite().save(f\"{base_path}/string_indexer_{idx}.bin\")\n",
    "\n",
    "# Guarda todos los OneHotEncoder\n",
    "for idx, encoder_model in enumerate(encoders):\n",
    "    encoder_model.write().overwrite().save(f\"{base_path}/one_hot_encoder_{idx}.bin\")\n",
    "\n",
    "# Guarda el modelo entrenado\n",
    "tvs_model.write().overwrite().save(f\"{base_path}/pipeline_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Food Delivery: Timing is everything",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5072200,
     "sourceId": 8499662,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
